{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DMTX2410/TL-P1/blob/Daniel/TL_P1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Práctica #1: Modelo para predicción de lluvia**\n",
        "\n",
        "*Centro Universitario de Ciencias Exactas e Ingenierías*\n",
        "\n",
        "*División de Tecnologías para la Integración Ciber-Humana*\n",
        "\n",
        "*Ingeniería Biomédica*\n",
        "\n",
        "<br>\n",
        "\n",
        "*Mtra. Sofía Alejandra Aguilar Valdez*\n",
        "\n",
        "2 de septiembre de 2022"
      ],
      "metadata": {
        "id": "nVx-kou4pjFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Información del equipo**\n",
        "\n",
        "```NOMBRES:```\n",
        "\n",
        "*   Jafet Daniel Manrique Torres\n",
        "*   \n",
        "*   \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "```CÓDIGOS:```\n",
        "*   217467298\n",
        "*   Elemento de la lista\n",
        "\n",
        "\n",
        "\n",
        "```LINK REPOSITORIO:```\n",
        "https://github.com/DMTX2410/TL-P1.git\n"
      ],
      "metadata": {
        "id": "dQNzG9Wm4ZQJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Contenido**\n",
        "\n",
        "\n",
        "\n",
        "1.   Resumen\n",
        "2.   Marco teórico\n",
        "3.   Objetivos\n",
        "4.   Materiales y métodos\n",
        "5.   Resultados\n",
        "6.   Discusión\n",
        "7.   Conclusiones\n",
        "8.   Referencias\n",
        "\n"
      ],
      "metadata": {
        "id": "QQ_tQMMJpude"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Resumen**\n",
        "\n",
        "La implementación de una red neuronal multicapa supervisada para predecir un conjunto de datos meteorológicos que permite adquirir los conocimientos sobre funcionamiento y comportamiento en base a los datos de entrenamiento y validación, para ello se utiliza biblioteca comoKeras y bibliotecas relacionadas que permiten desarrollar este tipo de redes complejas de manera sencilla gracias a sus funciones y clases. Para poder manipular los datos se transforman a tensores, para posterior definir los datos de entrenamiento y validación, parte clave es convertir estos datos en data loaders, en donde se definen los tamaños de los batch a usar. El tipo de predicciones depende de la elección de la función de activación. Por lo que para este tipo de caso se opta por usar la función ReLu en las capas, para este modelo se utiliza un total de 64 entradas con una dimensión de 3 en la capa de entrada y 1 una capa de salida. Con todo lo anterior definido se entrena a la red con una función de costo CrossEntropy permitiendo ajustar los pesos mediante backpropagation y un algoritmo de optimización Adam. Para el entrenamiento definen los hiperparametros como las épocas a usar que en este caso es de 10. Mediante el análisis de los resultados obtenidos del entrenamiento y evaluación se determina si el modelo tiende al underfitting o overfitting. \n"
      ],
      "metadata": {
        "id": "anvzyOk06GH5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Marco teórico**\n",
        "(300-800 palabras)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "E8r4C9H26UTK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Objetivos**\n",
        "Objetivo general y objetivos específicos"
      ],
      "metadata": {
        "id": "Tcx3QvQN6hWe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Materiales y métodos**\n",
        "\n",
        "## *Materiales*\n",
        "\n",
        "Los datos fueron recopilados del Aeropuerto Internacional de Seattle-Tacoma. El conjunto de datos contiene cinco columnas:\n",
        "\n",
        "*   FECHA = la fecha de la observación\n",
        "*   PRCP = la cantidad de precipitación, en pulgada\n",
        "*   TMAX = la temperatura máxima para ese día, en grados Fahrenheit\n",
        "*   TMIN = la temperatura mínima para ese día, en grados Fahrenheit\n",
        "*   LLUVIA = VERDADERO si se observó lluvia ese día, FALSO si no fuera así\n",
        "\n",
        "## *Métodos*"
      ],
      "metadata": {
        "id": "4rX1w4ZD6mPj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Código:**"
      ],
      "metadata": {
        "id": "213q52DWft4Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importamos las librerias\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "from keras.layers import Dense\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout"
      ],
      "metadata": {
        "id": "XeHyf3zpd1SK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Se carga el archivo que contiene los datos\n",
        "filepath = \"https://raw.githubusercontent.com/DMTX2410/TL-P1/main/seattleWeather_1948-2017.csv\" #Se guarda la ruta en la variable filepath\n",
        "df = pd.read_csv(filepath) #Se asignan los datos de la ruta a la variable df"
      ],
      "metadata": {
        "id": "_s3D_Yk7fNer"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Se convierte la columna de lluvia a valores enteros y se guardan en una nueva columna \"rain\"\n",
        "df['rain']=[1 if i==True else 0 for i in df['RAIN']] #Definimos como 1 si el valor es verdadero y como 0 si el valor es falso."
      ],
      "metadata": {
        "id": "QMmEWn5GfPQT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Se eliminan los valores nulos\n",
        "df.dropna(inplace=True) # El metodo dropna permite filtrar los valores de una estructura de datos pandas para dejar solo aquellos no nulos."
      ],
      "metadata": {
        "id": "mY7P4ac7fQ7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Definimos X y Y\n",
        "x = df[['PRCP', 'TMAX', 'TMIN']] #Aqui definimos que solo estas 3 columnas se guardaran en x\n",
        "y = df['rain'] #rain al ser el valor con el cual se valida, se guarda en Y"
      ],
      "metadata": {
        "id": "bChW4lC5fS69"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Se definen las variables de entrenamiento\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=42)#Se deja un tamaño de entrenamiento del 80%"
      ],
      "metadata": {
        "id": "o3dWpXqDfU5S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Usamos el modelo secuencial de Keras\n",
        "def build_model(): #Se define como función\n",
        "  model = keras.Sequential()\n",
        "  #Se usa una función de activacion de tipo relu, debido a la eficacia de esta en este tipo de casos\n",
        "  model.add(keras.layers.Dense(64, activation='relu', input_dim=x.shape[1]))#La capa de entrada tendra un total de 64 neuronas\n",
        "  model.add(keras.layers.Dense(32, activation='relu'))#La capa oculta tendra un total de 32 neuronas\n",
        "  model.add(keras.layers.Dense(1, activation='sigmoid'))#La capa de salida tendra solo una, la función de activación sera de tipo sigmoide debido al tipo de capa.\n",
        "  model.compile(optimizer= \"adam\", loss='binary_crossentropy', metrics=['accuracy'])\n",
        "  #Se especifica la forma como se calcularán los parámetros de la línea recta (w y b). \n",
        "  #Para ello se utiliza adam como modelo de optimizacion y crossentropy para determinar los pesos mediante backpropagation\n",
        "  return model"
      ],
      "metadata": {
        "id": "J7qXUNfNfXQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Detalles del modelo\n",
        "model = build_model()#Instanciamos el modelo\n",
        "model.summary()#Nos permite ver los parametros del modelo"
      ],
      "metadata": {
        "id": "yq-FdGVEfY5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Entrenamos la red neuronal\n",
        "history = model.fit(x_train, y_train, batch_size=10, epochs=10,validation_split =0.2,verbose=2)\n",
        "#Le asignamos un batch de 10 y epocas de 10, esto con el fin de obtener una precision alta a menor cantidad de epocas.\n",
        "#Para la validacion utilizaremos el 20% de las pruebas. "
      ],
      "metadata": {
        "id": "cXcqJgSnfa_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Grafica de perdidas vs iteraciones\n",
        "hist = pd.DataFrame(history.history)#Extraemos los datos del entrenamiento y validación\n",
        "hist['epoch'] = history.epoch #Asignamos el valor de las epocas\n",
        "plt.figure() #Creamos la figura\n",
        "plt.xlabel('Epoch')#Se asigna el nombre del ehe x\n",
        "plt.ylabel('Loss')#Se asigna el nombre del ehe y\n",
        "plt.title('Perdidas vs Iteraciones')#Se asigna el nombre del titulo de la grafica\n",
        "plt.plot(hist['epoch'], hist['loss'], label = 'Train Error')#Graficamos los valores de entrenamiento\n",
        "plt.plot(hist['epoch'], hist['val_loss'], label = 'Test Error')#Graficamos los valores de validacion\n",
        "plt.ylim(0,0.5)#Definimos los limites de y\n",
        "plt.legend()#Ploteamos los nombres de las graficas\n"
      ],
      "metadata": {
        "id": "T8i0w4CafdQe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Precision de la neurona\n",
        "prediction_nn = model.predict(x_test) #Usamos la funcion de predict sobre la variable de test\n",
        "prediction_nn = [1 if y>=0.5 else 0 for y in prediction_nn]#Definimos los parametros\n",
        "print(classification_report(y_test, prediction_nn))#Imprimos los datos"
      ],
      "metadata": {
        "id": "RhSMPfQ_ffKq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5. Resultados**\n",
        "(300-800 palabras, incluir mínimo 2 figuras)."
      ],
      "metadata": {
        "id": "6s3y9-yUSCL9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6. Discusión**\n",
        "Underfitting, overfitting, o no y el porqué\n",
        "Comparación de su metodología con literatura asociada"
      ],
      "metadata": {
        "id": "AEt8aII8SPu6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **7. Conclusiones**\n",
        "(100-300 palabras)."
      ],
      "metadata": {
        "id": "8Gb2ac0VSryX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **8. Referencias**\n",
        "\n",
        "[1] Pb, V. (2020, February 18). Perceptron. Kaggle. Retrieved June 1, 2022, from https://www.kaggle.com/code/prashfio/perceptron/notebook"
      ],
      "metadata": {
        "id": "cxRqAiW5sG_m"
      }
    }
  ]
}